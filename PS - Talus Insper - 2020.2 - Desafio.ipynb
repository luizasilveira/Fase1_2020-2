{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESSO SELETIVO TALUS INSPER 2020.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ol√°! Esse √© o Jupyter com o desafio do processo seletivo para a Talus!\n",
    "\n",
    "√â aqui que deve ser posta a resolu√ß√£o do desafio que iremos propor e nenhum outro material entregue junto com este ser√° considerado. Antes de continuarmos para o desafio, precisamos que voc√™ se identifique (usu√°rios n√£o identificados podem at√© passar, mas n√£o receber√£o notifica√ß√£o &#128521;\n",
    "\n",
    "Edite essa c√©lula e\n",
    "\n",
    "<font color='red'>Luiza Rodrigues Silveira</font>\n",
    "\n",
    "<font color='red'>luizars2@al.insper.edu.br</font>\n",
    "\n",
    "Se voc√™ tiver um usu√°rio do Discord\n",
    "\n",
    "<font color='red'>COLOQUE SEU USU√ÅRIO AQUI</font>\n",
    "\n",
    "Lembre que n√£o √© obrigat√≥rio Discord nessa etapa, mas ambas Segunda e Terceira Fase ser√£o realizadas por l√°. N√≥s estamos num servidor do Discord especial feito pra voc√™s, voc√™ pode passar l√° e tirar d√∫vidas com nossos membros a qualquer momento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regras do desafio\n",
    "\n",
    "O desafio que propomos aqui √© construir um modelo de regress√£o linear simples para apenas uma vari√°vel.\n",
    "\n",
    "Existem diversas maneiras de fazer isso, a maneira que iremos explicar aqui, e que voc√™ dever√° reproduzir, √© o m√©todo de Gradient Descent. Qualquer outro m√©todo que n√£o este __N√ÉO__ ser√° considerado.\n",
    "\n",
    "Uma an√°lise explorat√≥ria dos dados n√£o √© obrigat√≥ria e nem mesmo necess√°ria!\n",
    "\n",
    "Por √∫ltimo, vale frisar: a utiliza√ß√£o de pacotes com fun√ß√µes que cortem passos ou que fa√ßam o trabalho por voc√™ resultar√° na nulidade de sua solu√ß√£o e __N√ÉO__ ser√° considerado tamb√©m.\n",
    "\n",
    "No entanto, voc√™ pode usar os pacotes que foram ensinados no arquivo de tutorial para esse desafio.\n",
    "\n",
    "Voc√™ ir√° achar algumas c√©lulas com c√≥digo, elas servem para guiar voc√™, mas n√£o s√£o obrigat√≥rias! E voc√™ n√£o precisa usar a estrutura que propomos, mas deve seguir o roteiro que se encontra no fim do desafio!\n",
    "\n",
    "Boa sorte, n√≥s estamos esperando por voc√™ na Talus!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposta de desafio\n",
    "\n",
    "Como dito, o seu desafio ser√° transformar em c√≥digo a teoria sobre modelos de regress√£o linear que ser√° ensinada aqui.\n",
    "\n",
    "Voc√™ usar√° o c√≥digo que criou para prever o comportamento de uma vari√°vel em fun√ß√£o de outra, estas podem ser achadas no dataset 'desafio.csv' na pasta data. As vari√°veis foram geradas manualmente por n√≥s e portanto asseguramos que existe uma rela√ß√£o linear entre elas.\n",
    "\n",
    "No nosso dataset, a vari√°vel que ser√° prevista √© a vari√°vel y. N√£o existe um valor a ser batido, mas existem com certeza valores visivelmente incorretos. Seu c√≥digo n√£o ser√° avaliado apenas pelo valor dos coeficientes, mas tamb√©m (e principalmente) pela qualidade do c√≥digo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explica√ß√£o do modelo\n",
    "\n",
    "Sem entrarmos nos detalhes matem√°ticos (voc√™ ir√° aprender isso conosco depois), uma regress√£o linear √© um modelo capaz de computar o valor de uma vari√°vel atrav√©s de uma soma com pesos de outras vari√°veis mais a adi√ß√£o de uma constante (tamb√©m chamada de vi√©s ou intercepto). De maneira geral, uma rela√ß√£o linear entre vari√°veis pode ser expressa por:\n",
    "\n",
    "$$y = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + ... \\theta_nx_n$$\n",
    "\n",
    "Aqui trataremos apenas do caso $n = 1$, sendo $n$ o n√∫mero de features ou inputs do nosso modelo.\n",
    "\n",
    "Nessa equa√ß√£o, $\\theta_i$ √© o par√¢metro da feature $i$ sendo $\\theta_0$ o vi√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leia nessa c√©lula o dataset \"desafio.csv\" e obtenha os arrays de X e y\n",
    "\n",
    "dataset = pd.read_csv(\"data/desafio.csv\")\n",
    "\n",
    "X = dataset[\"X\"]\n",
    "y = dataset[\"y\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os algoritmos de regress√£o linear servem para acharmos, de maneira mais eficiente, os par√¢metros $\\theta$ de nosso modelo, definida uma m√©trica.\n",
    "\n",
    "Portanto, antes de falarmos como construirmos e treinarmos um modelo desses, √© preciso definir nossa m√©trica.\n",
    "\n",
    "Existem diversas m√©tricas de avalia√ß√£o quando falamos de modelos lineares, a mais popular e que usaremos aqui √© o __Erro Quadr√°tico M√©dio__ ou (EQM) que √© dado por:\n",
    "\n",
    "$$EQM(≈∑) = \\frac{1}{m}\\sum^m_{i=1}(≈∑_i - y_i)¬≤$$\n",
    "\n",
    "Onde:\n",
    "\n",
    "$m$ √© o n√∫mero de amostras usada no modelo;\n",
    "\n",
    "$≈∑$ √© o valor previsto por nosso modelo;\n",
    "\n",
    "$y$ √© o valor real da vari√°vel prevista.\n",
    "\n",
    "Substituindo a equa√ß√£o linear na f√≥rmula do EQM ficamos com:\n",
    "\n",
    "$$EQM(≈∑) = \\frac{1}{m}\\sum^m_{i=1}(\\theta_1{x_1}_i + \\theta_0 - y_i)¬≤$$\n",
    "\n",
    "E, portanto, vemos que $EQM$ depende do termo quadr√°tico de $\\theta_1$ e $\\theta_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crie aqui uma fun√ß√£o que calcule EQM\n",
    "# antes, lembre de inicializar o par√¢metro m do seu modelo\n",
    "\n",
    "m = dataset.shape[0]\n",
    "\n",
    "# os par√¢metros recebidos pela fun√ß√£o ficam a seu crit√©rio\n",
    "\n",
    "def calcula_eqm(m, theta0, theta1):\n",
    "    dataset = pd.read_csv(\"data/desafio.csv\")\n",
    "    X = dataset[\"X\"]\n",
    "    y = dataset[\"y\"]\n",
    "    soma = 0   \n",
    "    for i in range(0,m):\n",
    "        soma += (theta1*X[i] + theta0 - y[i])**2        \n",
    "        eqm = (1/m) * soma\n",
    "        \n",
    "    return eqm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como dito, existem v√°rias maneiras de encontrar os par√¢metros do nosso modelo, inclusive, um m√©todo bem mais simples do que o que vamos ensinar (mas que √© BEM mais lento para uma quantidade grande de dados).\n",
    "\n",
    "O m√©todo que usaremos se chama *Gradient Descent*, ele √© um algoritmo, ou melhor, uma fam√≠lia de algoritmos, bem simples e gen√©rico capaz de encontrar os par√¢metros de nossa regress√£o de uma maneira mais r√°pida, objetivando minimizar o valor do nosso erro, o $EQM$.\n",
    "\n",
    "Esse m√©todo consiste de inicializar, aleatoriamente, o valor dos par√¢metros e, iterativamente, modificar esse valor em fun√ß√£o do erro obtido.\n",
    "\n",
    "Para explicar bem o procedimento, vamos supor $\\theta_0$ (ou $\\theta_1$) constante. Nesse caso, ter√≠amos que $EQM$ √© uma fun√ß√£o quadr√°tica de $\\theta_1$, ou seja, uma par√°bola.\n",
    "\n",
    "Nesse caso, o gr√°fico de $EQM$ x $\\theta_1$ seria semelhante a:\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/600/1*iNPHcCxIvcm7RwkRaMTx1g.jpeg\" height=\"400\" width=\"600\">\n",
    "\n",
    "Onde cost √© a fun√ß√£o de custo, que no caso √© $EQM$.\n",
    "\n",
    "O que queremos √© dar, pequenos \"passos\", modificando $\\theta_1$ at√© alcan√ßarmos aquele que minimiza nosso erro.\n",
    "\n",
    "Caso voc√™ n√£o tenha entedido ainda, fa√ßamos um exerc√≠cio de imagina√ß√£o: imagine que voc√™ esteja preso no topo de uma montanha durante uma n√©voa muito densa, deixando de lado suas habilidades de alpinismo, uma maneira de achar a base da montanha seria deslizar seu p√© no ch√£o at√© achar a dire√ß√£o de descida e ent√£o dar pequenos passos nessa dire√ß√£o, √© exatamente isso que vamos fazer aqui.\n",
    "\n",
    "O learning step no nosso gr√°fico seria o tamanho do passo que voc√™ daria na montanha e a dire√ß√£o que seu p√© indicaria seria o qu√™? Vamos ver isso agora.\n",
    "\n",
    "Ah, e claro voc√™ esteja se co√ßando que n√£o resolvemos o caso real, com $n$ features, calma, n√£o √© o foco desse desafio e n√£o √© muito diferente da ideia que mostramos aqui, voc√™ s√≥ teria que ter uma abstra√ß√£o maior para desenhar o gr√°fico.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1098/1*yasmQ5kvlmbYMe8eDkyl6w.png\" height=\"400\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T√° certo, mas antes de falar sobre a dire√ß√£o do passo, √© importante falarmos algo sobre o learning step, ou learning rate como iremos chamar agora.\n",
    "\n",
    "Voc√™ se perguntou qual o valor que o learning rate deveria ter? Bom, n√≥s n√£o vamos te dar uma resposta sobre isso, mas vamos te mostrar o que o valor que voc√™ escolheu poderia resultar.\n",
    "\n",
    "Se voc√™ escolher um learning rate muito pequeno, o seu modelo precisaria de muito mais itera√ß√µes e execu√ß√µes para achar o valor de m√≠nimo. √â o equivalente a voc√™ dar passos que mal separam suas pernas tentando descer a montanha.\n",
    "\n",
    "J√° um learning rate muito grande corre o risco de passar do local de m√≠nimo.\n",
    "\n",
    "Veja essas imagens que exemplificam bem isso, mostrando um caso com learning rate pequeno e outro com learning rate muito grande, respectivamente:\n",
    "\n",
    "<div style=\"display: block\">\n",
    "<img src=\"./img/small_lr.png\" height=\"400\" width=\"600\">\n",
    "\n",
    "<img src=\"./img/large_lr.png\" height=\"400\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "O learning rate tamb√©m √© importante para se esquivar de m√≠nimos locais, mas voc√™ n√£o precisa se preocupar com isso aqui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicialize aqui os par√¢metros learning rate e o theta_0 e theta_1 inicial\n",
    "\n",
    "theta_0_ini = 0\n",
    "theta_1_ini = 0\n",
    "\n",
    "learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, agora vamos pro √∫ltimo fundamento (e o mais importante) pra que voc√™ possa concluir o desafio.\n",
    "\n",
    "A an√°logo matem√°tico da dire√ß√£o do seu passo tentando descer da montanha √© o que d√° nome a esse algoritmo, o *Gradiente*.\n",
    "\n",
    "Imaginamos que voc√™ esteja familiarizado com o conceito de derivada. Imagine no primeiro gr√°fico que lhe apresentamos que voc√™ tivesse que apontar a dire√ß√£o para onde o valor de $\\theta$ precisa andar, talvez voc√™ tenha feito com o dedo uma linha tangente apontando para o pr√≥ximo ponto do gr√°fico.\n",
    "\n",
    "Devemos achar a tangente, ou mais especificamente, o coeficiente angular desta, para encontrarmos a dire√ß√£o que devemos seguir a fim de minimizar nossa fun√ß√£o.\n",
    "\n",
    "E, uma luz pode ter acendido em voc√™, indicando o que ser√° necess√°rio para tal feito: as derivadas.\n",
    "\n",
    "Se calcularmos a derivada para $\\theta_0$ e $\\theta_1$ ter√≠amos:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial\\theta_0}EQM = \\frac{2}{m}\\sum^m_{i=1}(\\theta_1{x_1}_i + \\theta_0 - y_i)$$\n",
    "\n",
    "$$\\frac{\\partial}{\\partial\\theta_1}EQM = \\frac{2}{m}\\sum^m_{i=1}(\\theta_1{x_1}_i + \\theta_0 - y_i){x_1}_i$$\n",
    "\n",
    "O s√≠mbolo pode parecer diferente, mas a ideia √© a mesma, √© que nesse caso estamos falando de derivada parcial.\n",
    "\n",
    "Ah, e o motivo do nome gradiente, vem porque um gradiente basicamente √© um vetor formado pela derivada parcial das vari√°veis de que depende uma fun√ß√£o e indico sentido e a dire√ß√£o cujo deslocamento maximiza ou minimiza um valor especificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crie aqui as fun√ß√µes que calculam as derivadas parciais de theta_0 e theta_1\n",
    "# n√£o esque√ßa os par√¢metros\n",
    "\n",
    "def dif_theta_0(m,theta0, theta1):\n",
    "    dataset = pd.read_csv(\"data/desafio.csv\")\n",
    "    X = dataset[\"X\"]\n",
    "    y = dataset[\"y\"]\n",
    "    soma = 0   \n",
    "    for i in range(0,m-1, 1):\n",
    "        soma += (theta1*X[i] + theta0 - y[i])\n",
    "        \n",
    "    grad = soma * (2/m)\n",
    "    return grad\n",
    "    \n",
    "\n",
    "def dif_theta_1(m,theta0, theta1):\n",
    "    dataset = pd.read_csv(\"data/desafio.csv\")\n",
    "    X = dataset[\"X\"]\n",
    "    y = dataset[\"y\"]\n",
    "    soma = 0\n",
    "    for i in range(0,m-1, 1):\n",
    "        soma += (theta1*X[i] + theta0 - y[i])*X[i]\n",
    "    \n",
    "        \n",
    "    grad = soma * (2/m)\n",
    "    return grad\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, agora voc√™ tem tudo que precisa para montar o modelo, juntando todas as ideias obtidas at√© aqui, o processo por meio do qual voc√™ ir√° iterar os par√¢metros da sua regress√£o √© o seguinte:\n",
    "\n",
    "$$\\theta_{i+1} = \\theta_{i} - \\mu\\frac{\\partial}{\\partial\\theta}EQM$$\n",
    "\n",
    "Onde\n",
    "\n",
    "$\\theta_i$ √© o valor de $\\theta$ (0 ou 1) na i-√©sima itera√ß√£o;\n",
    "\n",
    "$\\mu$ √© o learning rate.\n",
    "\n",
    "Com isso, voc√™ pode achar o par√¢metros da regress√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crie aqui a fun√ß√£o que realiza a itera√ß√£o de theta\n",
    "\n",
    "def itera_theta(m,theta0_ini, theta1_ini, learning_rate):\n",
    "    theta_0 = theta0_ini\n",
    "    theta_1 = theta1_ini\n",
    "    for e in range(0,m-1,1) :\n",
    "        next_theta0 = theta_0 - (learning_rate * dif_theta_0(m,theta_0, theta_1))\n",
    "        theta_0 = next_theta0\n",
    "        next_theta1 = theta_1 - (learning_rate * dif_theta_1(m,theta_0, theta_1))\n",
    "        theta_1 = next_theta1\n",
    "\n",
    "    return theta_0, theta_1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pronto, a partir daqui √© com voc√™. Mas n√≥s vamos dar mais uma m√£ozinha. N√≥s preparamos um roteiro e __ATEN√á√ÉO__ todos os pontos s√£o __OBRIGAT√ìRIOS__ mas a execu√ß√£o √© totalmente por sua conta.\n",
    "\n",
    "- Leia o arquivo \"desafio.csv\" na pasta data\n",
    "- Obtenha as vari√°veis X e y no dataset\n",
    "- Inicialize (e deixe bem claro onde fez isso) os par√¢metros de seu modelo:\n",
    "    - Learning rate;\n",
    "    - N√∫mero de itera√ß√µes;\n",
    "    - N√∫mero de amostras;\n",
    "    - $\\theta_0$ e $\\theta_1$ iniciais, gerados aleatoriamente.\n",
    "- Desenvolva a fun√ß√£o que calcula EQM\n",
    "- Desenvolva uma (ou duas) fun√ß√µes que devolva a derivada parcial de EQM para cada um dos $\\theta$\n",
    "- Desenvolva a fun√ß√£o que itera $\\theta_0$ e $\\theta_1$ e devolva os valores finais\n",
    "- Plote um gr√°fico contendo:\n",
    "    - Os valores reais de X e y\n",
    "    - A reta formada pelos valores de $\\theta$ encontrados por voc√™\n",
    "    \n",
    "Ainda que voc√™ n√£o consiga concretizar um dos passos, N√ÉO desista. Novamente, o foco n√£o √© no resultado, mas na qualidade de seu c√≥digo.\n",
    "\n",
    "__BOA SORTE!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os par√¢metros recebidos pela fun√ß√£o ficam a seu crit√©rio\n",
    "\n",
    "#def calcula_eqm(m, theta0, theta1):\n",
    "#def dif_theta_0(m,theta0, theta1):\n",
    "#def itera_theta(m,theta0_ini, theta1_ini, learning_rate):\n",
    "\n",
    "t0 = itera_theta(m,theta_0_ini, theta_1_ini, learning_rate)[0]\n",
    "t1 = itera_theta(m,theta_0_ini, theta_1_ini, learning_rate)[1]\n",
    "eqm = calcula_eqm(m, t0, t1)\n",
    "\n",
    "#ùë¶=ùúÉ0+ùúÉ1ùë•1+ùúÉ2ùë•2+...ùúÉùëõùë•ùëõ\n",
    "novo_y = []\n",
    "for e in range(0,m):\n",
    "    novo_y.append(t0 + X[e]*t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(dataset['X'],dataset['y'])\n",
    "plt.plot(X,novo_y, color = \"green\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
